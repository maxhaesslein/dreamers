#!/usr/bin/python


# The Dreamers v4, 2023
# by maxhaesslein, 2014-2023
# www.maxhaesslein.de


# dependencies: opencv
# sudo apt install python3-opencv
# sudo apt install xserver-xorg xinit
#
# start with:
# startx /home/mh/dreamers/dreamers

# autostart happens in ~/.config/systemd/user/dreamers.service


print("")
print("###############################")
print("")
print("    THE DREAMERS v.4")
print("")
#print("    q: quit and shutdown")
#print("    e: exit to console")
print("    esc: exit")
print("  space: fake onset")
#print("    ,: decrease sensitivity")
#print("    .: increase sensitivity")
#print("    n: decrease speed")
#print("    m: increase speed")
#print("    s: sharpening overlay")
#print("    w: soundstream overlay")
#print("    p: pause rendering")
#print("    d: debug screen level")
#print("    v: verbose level")
print("")
print("###############################")


import numpy as np
from queue import Queue
import cv2
import time
import os
import random


options = {

    'videostreamCount': 4,
    'videostreamMaxQueueSize': 10,

    'screenWidth': 720,
    'screenHeight': 720,

    'fps': 30,

    'blankLoadingScreen': False,

    'windowName': 'The Dreamers',

    'debugFPS': True,
    'debugTiming': True,
    'debugStreams': True,

    'videoExtension': 'mp4',
    'videoPath': 'footage/',

    'verbose': True,

}


if options['verbose']:
    print('-- options --')
    print(options)



# setup window
cv2.namedWindow( options['windowName'], cv2.WINDOW_NORMAL )
cv2.resizeWindow( options['windowName'], options['screenWidth'], options['screenHeight'] )
cv2.setWindowProperty( options['windowName'], cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN )



# display startup image
startup_image = np.zeros((options['screenWidth'], options['screenHeight'], 3), np.uint8)
if not options['blankLoadingScreen']:

    font = cv2.FONT_HERSHEY_TRIPLEX # TODO: use custom font
    text = "The Dreamers"
    fontsize = 2
    fontwidth = 3
    textsize = cv2.getTextSize(text, font, fontsize, fontwidth)[0]
    textX = int((options['screenWidth'] - textsize[0]) / 2)
    textY = int((options['screenHeight'] - textsize[1]) / 2)
    cv2.putText(startup_image, text, (textX, textY), font, fontsize, (185,107,250), fontwidth)

    text = "loading ...".upper()
    fontsize = 1
    fontwidth = 1
    textsize = cv2.getTextSize(text, font, fontsize, fontwidth)[0]
    textX = int((options['screenWidth'] - textsize[0]) / 2)
    textY = int((options['screenHeight'] - textsize[1]))
    cv2.putText(startup_image, text, (textX, textY), font, fontsize, (255,255,255), fontwidth)

cv2.imshow(options['windowName'], startup_image)
cv2.waitKey(60)



# find videos:
videoFiles = [f for f in os.listdir(options['videoPath']) if os.path.isfile(os.path.join(options['videoPath'], f)) and f.lower().endswith(options['videoExtension'])]
if options['verbose']:
    print('-- video files --')
    print(str(len(videoFiles))+' videofiles')
    #print(videoFiles)




def drawDebugRect( im, x, y, w, h, p, c ):

    lineWidth = 1

    if p > 1.0:
        p = 1.0

    filledHeight = int(h * p)

    cv2.rectangle( im, (x,y), (x+w, y+h), c, lineWidth )
    cv2.rectangle( im, (x,y+h-filledHeight), (x+w, y+h), c, -1 )



class VideostreamProcessor():

    def __init__(self):

        self.streams = []
        self.index = 0

        for i in range(options['videostreamCount']):
            self.streams.append( self.loadVideo() )


    def loadVideo(self):

        videoFile = random.choice(videoFiles)
        videoIn = cv2.VideoCapture(options['videoPath']+videoFile)

        maxFrameCount = videoIn.get(cv2.CAP_PROP_FRAME_COUNT)
        if maxFrameCount > 100:
            startFrame = random.randint(0, maxFrameCount-100)
            videoIn.set( cv2.CAP_PROP_POS_FRAMES, startFrame )

        stream = {
            'queue': Queue(maxsize=options['videostreamMaxQueueSize']),
            'videoIn': videoIn,
            'videoFile': videoFile, # DEBUG
        }

        return stream


    def update(self):

        for stream in self.streams:
            #print('update #'+str(i)+' in stream '+str(stream['videoFile'])+' / Queue: '+str(stream['queue'].qsize())+' frames' )
            self.readFrameToQueue(stream)


    def readFrameToQueue(self, stream):

        if stream['queue'].full():
            #print('queue already full')
            return

        ret, frame = stream['videoIn'].read()

        if ret == False:
            # no more frames left, loop video
            stream['videoIn'].set(cv2.CAP_PROP_POS_FRAMES, 0)
            self.readFrameToQueue(stream) # re-run
            return

        stream['queue'].put(frame)


    def changeVideostreamIndex(self):

        randomIndex = random.randint(0, options['videostreamCount']-1)
        if randomIndex == self.index:
            # don't change to current stream, just abort here
            return

        self.index = randomIndex


    def changeVideostreamInput(self):

        randomIndex = random.randint(0, options['videostreamCount']-1)
        if randomIndex == self.index:
            # don't change current stream, just abort here
            return

        self.streams[randomIndex] = self.loadVideo()



    def getNextFrame(self):

        frame = self.streams[self.index]['queue'].get()

        return frame

    def getInfo(self):

        infos = []
        for stream in self.streams:
            infos.append(stream['queue'].qsize())

        return self.index, infos

    def release(self):
        for stream in self.streams:
            stream['videoIn'].release()



debugFont = cv2.FONT_HERSHEY_COMPLEX_SMALL

fps = 0
target_time = current_time = time.time()
previous_time = time.time()+1
loop_delta = 1./options['fps']
sleep_time = 0

videostreams = VideostreamProcessor()
videostreams.update()


# main loop
while True:

    start_time = time.time()

    videostreams.update()

    frame = videostreams.getNextFrame()

    # resize frame
    frameHeight, frameWidth, frameChannels = frame.shape
    targetWidth = options['screenWidth']
    targetHeight = int(targetWidth * frameHeight/frameWidth)
    if targetHeight < options['screenHeight']:
        targetHeight = options['screenHeight']
        targetWidth = int(targetHeight * frameWidth/frameHeight)

    marginX = int((targetWidth - options['screenWidth'])/2)
    marginY = int((targetHeight - options['screenHeight'])/2)

    im = cv2.resize( frame, (targetWidth, targetHeight) )

    im = im[marginY:marginY+options['screenHeight'], marginX:marginX+options['screenWidth']]

    if options['debugFPS']:
        color = (0,255,0)
        if fps >= 29 or fps <= 31:
            fps = 30

        if fps < 25:
            color = (255,0,0)
        elif fps < 30:
            color = (255,255,0)

        cv2.putText( im, str(fps), (10,20), debugFont, 1, color, 1, cv2.LINE_AA )

    if options['debugTiming']:

        maxTime = int(loop_delta*1000)

        color = (0,255,0)
        if sleep_time < maxTime * 0.2:
            color = (0,0,255)
        elif sleep_time < maxTime*0.4:
            color = (0,255,255)

        freePercent = (float(sleep_time)/float(maxTime))
        if freePercent < 0.1:
            freePercent = 0

        filledPercent = 1-freePercent

        w = 30
        h = 100
        x = options['screenWidth'] - w - 10
        y = options['screenHeight'] - h - 10

        drawDebugRect( im, x, y, w, h, filledPercent, color )

    if options['debugStreams']:
        streamIndex, queueSizes = videostreams.getInfo()

        w = 10
        h = 100
        x = 10
        y = options['screenHeight'] - h - 10


        for i, queueSize in enumerate(queueSizes):
            color = (0,255,0)
            if i == streamIndex:
                color = (0,0,255)
            filledPercent = float(queueSize/options['videostreamMaxQueueSize'])
            drawDebugRect( im, x, y, w, h, filledPercent, color )
            x += w+5


    cv2.imshow(options['windowName'], im)


    previous_time, current_time = current_time, time.time()
    fps = int(1./(current_time-previous_time))
    target_time += loop_delta
    sleep_time = int((target_time - current_time)*1000)
    if sleep_time < 1:
        sleep_time = 1

    key = cv2.waitKey(sleep_time)

    onset = False

    if key == 27: # escape
        break

    elif key == 32: # space
        onset = True


    if onset:
        if random.randint(0,1) == 1:
            videostreams.changeVideostreamIndex()
        else:
            videostreams.changeVideostreamInput()


print('bye!')

videostreams.release()
cv2.destroyAllWindows()

