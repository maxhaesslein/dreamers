#!/usr/bin/python


# The Dreamers v4, 2023
# by maxhaesslein, 2014-2023
# www.maxhaesslein.de


# dependencies: opencv
# sudo apt install python3-opencv
# sudo apt install xserver-xorg xinit
#
# start with:
# startx /home/mh/dreamers/dreamers

# autostart happens in ~/.config/systemd/user/dreamers.service


print("")
print("###############################")
print("")
print("    THE DREAMERS v.4")
print("")
#print("    q: quit and shutdown")
#print("    e: exit to console")
print("    esc: exit")
print("  space: fake onset")
print("      1: toggle effect 'colorMap'")
print("      2: toggle effect 'blur'")
print("      3: toggle effect 'edgeDetection'")
print("      4: toggle effect 'flip'")
print("      5: toggle effect 'sharpening'")
print("      6: toggle effect 'emboss'")
print("      7: toggle effect 'inverse'")
print("      8: toggle effect 'multiple'")
print("      0: toggle all effects")
#print("    ,: decrease sensitivity")
#print("    .: increase sensitivity")
#print("    n: decrease speed")
#print("    m: increase speed")
#print("    s: sharpening overlay")
#print("    w: soundstream overlay")
#print("    p: pause rendering")
#print("    d: debug screen level")
#print("    v: verbose level")
print("")
print("###############################")


from queue import Queue
from threading import Thread
import numpy as np
import cv2
import time
import os
import random


options = {

    'debugFPS': True,
    'debugTiming': True,
    'debugStreams': True,
    'debugEffects': True,

    'verbose': True,

    'fps': 30,

    'screenWidth': 720,
    'screenHeight': 720,


    'videostreamCount': 32,
    'videostreamMaxQueueSize': 20,

    'videoProcessorTimeout': 0.05,


    'windowName': 'The Dreamers',

    'videoExtension': 'mp4',
    'videoPath': 'footage/',

    'colorMaps': ["AUTUMN", "BONE", "JET", "WINTER", "RAINBOW", "OCEAN", "SUMMER", "SPRING", "COOL", "HSV", "PINK", "HOT"],

    'debugFont': cv2.FONT_HERSHEY_COMPLEX_SMALL,
}


maxVals = {
    'blur': 30,
    'edgeDetection': 10,
    'sharpening': 20,
    'emboss': 10
}


if options['verbose']:
    print('-- options --')
    print(options)



# setup window
cv2.namedWindow( options['windowName'], cv2.WINDOW_NORMAL )
cv2.resizeWindow( options['windowName'], options['screenWidth'], options['screenHeight'] )
cv2.setWindowProperty( options['windowName'], cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN )



# display startup image
startup_image = np.zeros((options['screenWidth'], options['screenHeight'], 3), np.uint8)
font = cv2.FONT_HERSHEY_TRIPLEX # TODO: use custom font
text = "The Dreamers"
fontsize = 2
fontwidth = 3
textsize = cv2.getTextSize(text, font, fontsize, fontwidth)[0]
textX = int((options['screenWidth'] - textsize[0]) / 2)
textY = int((options['screenHeight'] - textsize[1]) / 2)
cv2.putText(startup_image, text, (textX, textY), font, fontsize, (185,107,250), fontwidth)
text = "loading ...".upper()
fontsize = 1
fontwidth = 1
textsize = cv2.getTextSize(text, font, fontsize, fontwidth)[0]
textX = int((options['screenWidth'] - textsize[0]) / 2)
textY = int((options['screenHeight'] - textsize[1]))
cv2.putText(startup_image, text, (textX, textY), font, fontsize, (255,255,255), fontwidth)
cv2.imshow(options['windowName'], startup_image)
cv2.waitKey(60)



# find videos:
videoFiles = [f for f in os.listdir(options['videoPath']) if os.path.isfile(os.path.join(options['videoPath'], f)) and f.lower().endswith(options['videoExtension'])]
if options['verbose']:
    print('-- video files --')
    print(str(len(videoFiles))+' videofiles')
    #print(videoFiles)




def drawDebugRect( im, x, y, w, h, p, c ):

    lineWidth = 1

    if p > 1.0:
        p = 1.0

    filledHeight = int(h * p)

    cv2.rectangle( im, (x,y), (x+w, y+h), c, lineWidth )
    cv2.rectangle( im, (x,y+h-filledHeight), (x+w, y+h), c, -1 )



class VideostreamProcessor():

    def __init__(self):

        self.running = True

        self.streams = []
        self.index = 0

        for i in range(options['videostreamCount']):
            self.streams.append( self.loadVideo() )


    def start(self):
        t = Thread(target=self.update, args=())
        t.daemon = True
        t.start()
        return self


    def loadVideo(self):

        videoFile = random.choice(videoFiles)
        videoIn = cv2.VideoCapture(options['videoPath']+videoFile)

        # we currently start always at the beginning of the video; seeking may add framedrops
        #maxFrameCount = videoIn.get(cv2.CAP_PROP_FRAME_COUNT)
        #if maxFrameCount > 100:
        #    startFrame = random.randint(0, maxFrameCount-100)
        #    videoIn.set( cv2.CAP_PROP_POS_FRAMES, startFrame )

        stream = {
            'queue': Queue(maxsize=options['videostreamMaxQueueSize']),
            'videoIn': videoIn,
        }

        return stream


    def update(self):

        while self.running:

            # first, fill up current stream
            currentStream = self.streams[self.index]
            while not currentStream['queue'].full():
                self.readFrameToQueue(currentStream)

            # then fill up rest:
            for stream in self.streams:
                self.readFrameToQueue(stream)

            time.sleep(options['videoProcessorTimeout'])


    def stop(self):
        self.running = False
        for stream in self.streams:
            stream['videoIn'].release()


    def readFrameToQueue(self, stream):

        if stream['queue'].full():
            #print('queue already full')
            return

        ret, frame = stream['videoIn'].read()

        if ret == False:
            # no more frames left, loop video
            stream['videoIn'].set(cv2.CAP_PROP_POS_FRAMES, 0)
            return

        stream['queue'].put(frame)


    def changeVideostreamIndex(self):

        randomIndex = random.randint(0, options['videostreamCount']-1)
        if randomIndex == self.index:
            # don't change to current stream, just abort here
            return

        self.index = randomIndex


    def changeVideostreamInput(self):

        randomIndex = random.randint(0, options['videostreamCount']-1)
        if randomIndex == self.index:
            # don't change current stream, just abort here
            return

        self.streams[randomIndex] = self.loadVideo()


    def getNextFrame(self, blocking = False):

        if not self.running:
            return false

        frame = self.streams[self.index]['queue'].get(blocking)

        return frame

    def getInfo(self):

        infos = []
        for stream in self.streams:
            infos.append(stream['queue'].qsize())

        return self.index, infos


class EffectProcessor():

    def __init__(self):

        self.queueInput = Queue(maxsize=1)
        self.queueOutput = Queue(maxsize=1)
        self.running = True

        self.kernels = {
            'edgeDetection': np.array([ [-1,-1,-1], [-1, 8,-1], [-1,-1,-1] ]),
            'sharpening':    np.array([ [ 1,-3, 1], [-1, 9,-1], [-1,-3,-1] ]),
            'emboss':    np.array([ [-3, -3,-3], [-4,-4,-4], [ 7, 8, 7] ])
        }

        self.options = {
            'colorMap': 0,
            'blur': [0,0],
            'edgeDetection': 0,
            'flip': 0,
            'sharpening': 0,
            'emboss': 0,
            'inverse': 0,
            'multiple': 0,
        }

        self.active = {
            'colorMap': True,
            'blur': True,
            'edgeDetection': True,
            'flip': True,
            'sharpening': True,
            'emboss': True,
            'inverse': True,
            'multiple': True,
        }

        self.colorMaps = []
        for colorMap in options['colorMaps']:
            self.colorMaps.append(getattr(cv2, "COLORMAP_"+colorMap))

        gamma = 1.0 # 0.0 - 1.0 --> different gamma values
        invGamma = 1.0 / gamma
        inverseLut = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
        self.luts = {
            'inverse': inverseLut[::-1]
        }


    def start(self):
        t = Thread(target=self.update, args=())
        t.daemon = True
        t.start()
        return self


    def update(self):
        while self.running:
            frame = self.queueInput.get(True)

            frame = self.apply(frame)

            self.queueOutput.put(frame)


    def put(self, frame):
        self.queueInput.put(frame)


    def get(self):
        return self.queueOutput.get()


    def apply(self, frame):

        # convert to grayscale for faster effect computation
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # inverse
        if self.active['inverse'] and self.options['inverse'] > 0:
            frame = cv2.LUT(frame, self.luts['inverse'])

        # flip
        if self.active['flip'] and self.options['flip'] > 0:
            frame = cv2.flip(frame, 1)

        # edge detection
        if self.active['edgeDetection'] and self.options['edgeDetection'] > 0:
            frame = cv2.filter2D(frame, -1, self.kernels['edgeDetection'])
            self.options['edgeDetection'] -= 1

        # blur image
        if self.active['blur'] and (self.options['blur'][0] > 1 or self.options['blur'][1] > 1):
            frame = cv2.blur(frame, (self.options['blur'][0], self.options['blur'][1]))
            self.options['blur'][0] -= 1
            if self.options['blur'][0] < 1: self.options['blur'][0] = 1
            self.options['blur'][1] -= 1
            if self.options['blur'][1] < 1: self.options['blur'][1] = 1

        # sharpening
        if self.active['sharpening'] and self.options['sharpening'] > 0:
            frame = cv2.filter2D(frame, -1, self.kernels['sharpening'])
            self.options['sharpening'] -= 1

        # emboss
        if self.active['emboss'] and self.options['emboss'] > 0:
            frame = cv2.filter2D(frame, -1, self.kernels['emboss'])
            self.options['emboss'] -= 1

        # show frame multiple times
        if self.active['multiple'] and self.options['multiple']:
            if self.options['multiple'] == 2:
                frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5) # resize two half the size
                frame = np.concatenate((frame, frame), axis=0) # stack vertically
                frame = np.concatenate((frame, frame), axis=1) # stack horizontally
            elif self.options['multiple'] == 3:
                frame = cv2.resize(frame, (0,0), fx=0.333, fy=0.333)
                frame = np.concatenate((frame, frame, frame), axis=0)
                frame = np.concatenate((frame, frame, frame), axis=1)
            elif self.options['multiple'] == 4:
                frame = cv2.resize(frame, (0,0), fx=0.25, fy=0.25)
                frame = np.concatenate((frame, frame, frame, frame), axis=0)
                frame = np.concatenate((frame, frame, frame, frame), axis=1)
            elif self.options['multiple'] == 5:
                frame = cv2.resize(frame, (0,0), fx=0.2, fy=0.2)
                frame = np.concatenate((frame, frame, frame, frame, frame), axis=0)
                frame = np.concatenate((frame, frame, frame, frame, frame), axis=1)
            elif self.options['multiple'] == 6:
                frame = cv2.resize(frame, (0,0), fx=0.167, fy=0.167)
                frame = np.concatenate((frame, frame, frame, frame, frame, frame), axis=0)
                frame = np.concatenate((frame, frame, frame, frame, frame, frame), axis=1)

        # convert back to bgr
        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)

        # tint image
        if self.active['colorMap'] and self.options['colorMap'] > 0:
            frame = cv2.applyColorMap(frame, self.colorMaps[self.options['colorMap']-1])

        return frame


    def activate(self, effect = False):

        if not effect:
            effect = random.choice(list(self.active))

        if not self.active[effect]:
            if options['verbose']:
                print(' (effect '+str(effect)+' is not active')
            return

        if options['verbose']:
            print('activating effect '+str(effect))

        # set colormap
        if effect == 'colorMap':
            self.options['colorMap'] = random.randint(0, len(self.colorMaps))
            if options['verbose']: print('changed colorMap to '+str(self.options['colorMap']))

        # set blur
        elif effect == 'blur':
            self.options['blur'] = [random.randint(4, maxVals['blur']), random.randint(4, maxVals['blur'])]
            if options['verbose']: print('set blur to '+str(self.options['blur']))

        # set edge detection
        elif effect == 'edgeDetection':
            self.options['edgeDetection'] = random.randint(2, maxVals['edgeDetection'])
            if options['verbose']: print('set edge detection to '+str(self.options['edgeDetection']))

        # set flip
        elif effect == 'flip':
            self.options['flip'] = random.randint(0,1)
            if options['verbose']: print('set image flip to '+str(self.options['flip']))

        # set sharpening
        elif effect == 'sharpening':
            self.options['sharpening'] = random.randint(2, maxVals['sharpening'])
            if options['verbose']: print('set sharpening to '+str(self.options['sharpening']))

        # set emboss
        elif effect == 'emboss':
            self.options['emboss'] = random.randint(2, maxVals['emboss'])
            if options['verbose']: print('set sharpening to '+str(self.options['emboss']))

        # set inverse
        elif effect == 'inverse':
            self.options['inverse'] = random.randint(0,1)
            if options['verbose']: print('set inverse to '+str(self.options['flip']))

        #set multiple
        elif effect == 'multiple':
            if random.randint(0,10) > 7:
                self.options['multiple'] = random.randint(2, 3)
            else:
                self.options['multiple'] = random.randint(4, 6)
            if options['verbose']: print('set multiple to '+str(self.options['multiple']))


    def toggle(self, effect, setToBool = 'none' ):

        if effect == 'all':
            setToBool = not self.active['colorMap'] # we use the value of the first effect to toggle
            for effect in self.active:
                self.toggle(effect, setToBool)
            return

        print('setToBool '+str(setToBool))

        if setToBool is 'none':
            # toggle
            self.active[effect] = not self.active[effect]
        else:
            # set to value
            self.active[effect] = setToBool

        if effect == 'blur':
            self.options[effect] = [0,0]
        else:
            self.options[effect] = 0

        if options['verbose']:
            print('set effect '+str(effect)+' to '+str(self.active[effect]))


    def getInfo(self):
        return self.active, self.options


    def stop(self):
        self.running = False



fps = 0
targetTime = 1./options['fps']
previousTime = currentTime = time.time()
sleep_time = 0

videostreams = VideostreamProcessor().start()
effects = EffectProcessor().start()

lastFrame = videostreams.getNextFrame(True)
effects.put(lastFrame)

time.sleep(1)

# main loop
while True:

    startTime = time.time()

    nextFrame = videostreams.getNextFrame()
    if type(nextFrame) == type(None): # no frame retreived, use last frame
        nextFrame = lastFrame

    lastFrame = nextFrame

    frame = effects.get()
    effects.put(nextFrame)

    # resize frame
    frameHeight, frameWidth, frameChannels = frame.shape
    targetWidth = options['screenWidth']
    targetHeight = int(targetWidth * frameHeight/frameWidth)
    if targetHeight < options['screenHeight']:
        targetHeight = options['screenHeight']
        targetWidth = int(targetHeight * frameWidth/frameHeight)

    marginX = int((targetWidth - options['screenWidth'])/2)
    marginY = int((targetHeight - options['screenHeight'])/2)

    im = cv2.resize( frame, (targetWidth, targetHeight) )

    im = im[marginY:marginY+options['screenHeight'], marginX:marginX+options['screenWidth']]

    if options['debugFPS']:
        color = (0,255,0)

        if fps < 25:
            color = (255,0,0)
        elif fps < 30:
            color = (255,255,0)

        cv2.putText( im, str(fps), (options['screenWidth']-30, 30), options['debugFont'], 1, color, 1, cv2.LINE_AA )

    if options['debugTiming']:

        maxTime = int(targetTime*1000)

        color = (0,255,0)
        if sleep_time < maxTime * 0.2:
            color = (0,0,255)
        elif sleep_time < maxTime*0.4:
            color = (0,255,255)

        freePercent = (float(sleep_time)/float(maxTime))
        if freePercent < 0.1:
            freePercent = 0

        filledPercent = 1-freePercent

        w = 30
        h = 100
        x = options['screenWidth'] - w - 10
        y = options['screenHeight'] - h - 10

        drawDebugRect( im, x, y, w, h, filledPercent, color )

    if options['debugStreams']:
        streamIndex, queueSizes = videostreams.getInfo()

        w = 10
        h = 100
        x = 10
        y = options['screenHeight'] - h - 10

        for i, queueSize in enumerate(queueSizes):
            color = (0,255,0)
            if i == streamIndex:
                color = (0,0,255)
            filledPercent = float(queueSize/options['videostreamMaxQueueSize'])
            drawDebugRect( im, x, y, w, h, filledPercent, color )
            x += w+5

    if options['debugEffects']:
        activeEffects, effectOptions = effects.getInfo()

        w = 20
        h = 50
        x = 10
        y = 10

        for key, val in effectOptions.items():
            key_text = key

            if activeEffects[key]:
                color = (255,255,255)
            else:
                color = (0,0,0)
                val = 0

            maxVal = 1

            if key == 'colormap':
                maxVal = len(options['colorMaps'])
                w = 60
            elif key == 'blur':
                maxVal = maxVals['blur']
                if not activeEffects[key]:
                    val = (0,0)

                filledPercent = val[0]/maxVal
                drawDebugRect( im, x, y, w, h, filledPercent, color )
                x += w+5
                val = val[1]

            elif key == 'edgeDetection':
                maxVal = maxVals['edgeDetection']
                key_text = 'edg'
            elif key == 'sharpening':
                maxVal = maxVals['sharpening']
                key_text = 'shrp'
            elif key == 'emboss':
                maxVal = maxVals['emboss']
                key_text = 'emb'
            elif key == 'inverse':
                key_text = 'inv'
            elif key == 'multiple':
                val -= 1
                if val < 0:
                    val = 0
                maxVal = 5
                key_text = 'mult'

            filledPercent = val/maxVal

            drawDebugRect( im, x, y, w, h, filledPercent, color )
            cv2.putText( im, key_text, (x, y+h+8), options['debugFont'], 0.4, color, 1, cv2.LINE_AA )

            x += w+5


    cv2.imshow(options['windowName'], im)


    previousTime, currentTime = currentTime, time.time()
    usedTime = currentTime - startTime
    timeLeft = targetTime-usedTime
    fps = int(1./(currentTime-previousTime))
    sleep_time = int((timeLeft)*1000)
    print(sleep_time)
    if sleep_time < 1:
        sleep_time = 1

    key = cv2.waitKey(sleep_time)

    onset = False

    if key == 27: # escape
        break

    elif key == 32: # space
        onset = True

    elif key&0xFF == ord('i'):
        videostreams.changeVideostreamIndex()

    elif key&0xFF == ord('c'):
        videostreams.changeVideostreamInput()

    elif key&0xFF == ord('0'):
        effects.toggle('all')
    elif key&0xFF == ord('1'):
        effects.toggle('colorMap')
    elif key&0xFF == ord('2'):
        effects.toggle('blur')
    elif key&0xFF == ord('3'):
        effects.toggle('edgeDetection')
    elif key&0xFF == ord('4'):
        effects.toggle('flip')
    elif key&0xFF == ord('5'):
        effects.toggle('sharpening')
    elif key&0xFF == ord('6'):
        effects.toggle('emboss')
    elif key&0xFF == ord('7'):
        effects.toggle('inverse')
    elif key&0xFF == ord('8'):
        effects.toggle('multiple')

    if onset:
        # TODO: maybe change effects
        randomNumber = random.randint(0,4)
        if randomNumber == 1:
            videostreams.changeVideostreamIndex()
        elif randomNumber == 2:
            videostreams.changeVideostreamInput()
        else:
            effects.activate()


print('bye!')

effects.stop()
videostreams.stop()

cv2.destroyAllWindows()

