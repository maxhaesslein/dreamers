#!/usr/bin/python


# The Dreamers v4, 2023
# by maxhaesslein, 2014-2023
# www.maxhaesslein.de


print("")
print("###############################")
print("")
print("    THE DREAMERS v.4")
print("")
#print("    q: quit and shutdown")
print("    esc: exit to console")
print("  space: fake onset")
print('')
print("      1: toggle effect 'colorMap'")
print("      2: toggle effect 'blur'")
print("      3: toggle effect 'edgeDetection'")
print("      4: toggle effect 'flip'")
print("      5: toggle effect 'sharpening'")
print("      6: toggle effect 'emboss'")
print("      7: toggle effect 'inverse'")
print("      8: toggle effect 'multiple'")
print("      9: toggle effect 'staggered'")
print("      0: toggle effect 'text'")
print("      a: toggle all effects")
print('')
print("      q: toggle FPS debug display")
print("      w: toggle timing debug display")
print("      e: toggle videostreams debug display")
print("      r: toggle effects debug display")
print("      t: toggle audio debug display")
print("      z: toggle onset debug display")
print("      d: toggle all debug displays")
print('')
print("      ,: decrease sensitivity")
print("      .: increase sensitivity")
print("      p: pause rendering")
#print("    v: verbose level")
print("")
print("###############################")


from queue import Queue
from threading import Thread
from configparser import ConfigParser
import numpy as np
import cv2
import time
import os
import sys
import random
import math
import pyaudio
import aubio


options = {

    'debugFPS': False,
    'debugTiming': False,
    'debugStreams': False,
    'debugEffects': False,
    'debugAudio': False,
    'debugOnset': False,

    'verbose': True,


    'fps': 24,
    'fpsSmoothing':  0.6, # this smoothes only the fps _debug display_, NOT the real fps

    'screenWidth': 1280,
    'screenHeight': 720,


    'effectsActive': True,
    'frameResize': False, # can be False (no resize, default), 'load' (resize on load), 'pre' (resize before effect) or 'post' (resize after effect)
    'effectsMultithreaded': True, # runs faster, but has 1 frame delay

    'grayscale': False,

    'videostreamCount': 20, # use ~10 for 2 GB RAM, ~20 for 4 GB RAM
    'videostreamMaxQueueSize': 20,


    'sensitivity': 0.3, # lower means slower, higher means faster; 0.1 - 2.0

    'windowName': 'The Dreamers',

    'videoExtension': 'mp4',
    'videoPath': 'footage/',

    'debugFont': cv2.FONT_HERSHEY_COMPLEX_SMALL,

    'audioDevice': 'auto',
    'audioDisplayScaling': 3000,

    'initSleepTime': 5, # in seconds, sleep time after loading videostreams before starting main loop


    'effectsActiveList': {
        'colorMap': False,
        'blur': False,
        'edgeDetection': False,
        'flip': True,
        'sharpening': False,
        'emboss': False,
        'inverse': False,
        'multiple': True,
        'staggered': True,
        'text': False,
    },
    'colorMaps': ["AUTUMN", "BONE", "JET", "WINTER", "RAINBOW", "OCEAN", "SUMMER", "SPRING", "COOL", "HSV", "PINK", "HOT"],

    'fontFile': False,
    'fontSize': 4,

    'texts': [ "OBEY", "CONSUME", "FOLLOW" ]

}


# probabilites:
# the higher the number, the less likely the hit; 0 means hit every time
probabilities = {
    'changeVideoStream': 3,
    #'repeatVideoStream': 25, # fires on changeVideoStream if there is at least a buffer worth of frames # TODO
    'changeColorMap': 20,
    'setBlur': 125,
    'setEdgeDetection': 160,
    'setFlip': 200,
    'unsetFlip': 40,
    'setSharpening': 110,
    'setEmboss': 125,
    'setInverse': 80,
    'unsetInverse': 12,
    'setMultiple': 120,
    'unsetMultiple': 60,
    'setStaggered': 120,
    'unsetStaggered': 60,
    'setText': 80,
}

minVals = {
    'blur': 4,
    'edgeDetection': 2,
    'sharpening': 2,
    'emboss': 2,
    'text': 6,
    'multiple': 2,
    'staggered': 4,
}
maxVals = {
    'blur': 30,
    'edgeDetection': 10,
    'sharpening': 20,
    'emboss': 10,
    'text': 6,
    'multiple': 6,
    'staggered': 6,
}


# check for config file and read options
if os.path.isfile('dreamers.ini'):
    configParser = ConfigParser()
    configParser.read('dreamers.ini')

    intOptions = [ 'fps', 'screenWidth', 'screenHeight', 'videostreamCount', 'videostreamMaxQueueSize', 'audioDisplayScaling', 'initSleepTime', 'fontSize' ]
    floatOptions = [ 'fpsSmoothing', 'sensitivity' ]

    for option in options:

        if configParser.has_option('Dreamers', option):

            if option in intOptions:
                options[option] = configParser.getint('Dreamers', option)
            elif option in floatOptions:
                options[option] = configParser.getfloat('Dreamers', option)
            else:
                options[option] = configParser.get('Dreamers', option)

            if options[option] == "False":
                options[option] = False
            elif options[option] == "True":
                options[option] = True




# setup window
cv2.namedWindow( options['windowName'], cv2.WINDOW_NORMAL )
cv2.resizeWindow( options['windowName'], options['screenWidth'], options['screenHeight'] )
cv2.setWindowProperty( options['windowName'], cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN )


# setup custom font
customFont = False
if options['fontFile']:
    customFont = cv2.freetype.createFreeType2()
    customFont.loadFontData( fontFileName=options['fontFile'], id=0 )


# display startup image
startupImage = np.zeros((options['screenHeight'], options['screenWidth'], 3), np.uint8)
font = cv2.FONT_HERSHEY_TRIPLEX
text = "The Dreamers"
fontSize = 2
fontWidth = 3
color = (185,107,250)
if customFont:
    fontSize = fontSize * 40
    textSize = customFont.getTextSize(text, fontSize, fontWidth)[0]
    textX = int((options['screenWidth'] - textSize[0]) / 2)
    textY = int((options['screenHeight'] - textSize[1]) / 2)
    customFont.putText( img=startupImage, text=text, org=(textX, textY), fontHeight=fontSize, color=color, thickness=-1, line_type=cv2.LINE_AA, bottomLeftOrigin=True )
else:
    textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
    textX = int((options['screenWidth'] - textSize[0]) / 2)
    textY = int((options['screenHeight'] - textSize[1]) / 2)
    cv2.putText( img=startupImage, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=color, thickness=fontWidth, lineType=cv2.LINE_AA )

text = "loading ..."
fontSize = 1
fontWidth = 1
color = (255,255,255)
if customFont:
    fontSize = fontSize * 40
    textSize = customFont.getTextSize(text, fontSize, fontWidth)[0]
    textX = int((options['screenWidth'] - textSize[0]) / 2)
    textY = int((options['screenHeight'] - textSize[1]*2))
    customFont.putText( img=startupImage, text=text, org=(textX, textY), fontHeight=fontSize, color=color, thickness=-1, line_type=cv2.LINE_AA, bottomLeftOrigin=True )
else:
    textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
    textX = int((options['screenWidth'] - textSize[0]) / 2)
    textY = int((options['screenHeight'] - textSize[1]*2))
    cv2.putText( img=startupImage, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=color, thickness=fontWidth, lineType=cv2.LINE_AA )

cv2.imshow(options['windowName'], startupImage)
cv2.waitKey(60)


# get audio input options
pa = pyaudio.PyAudio()
if options['verbose']:
    print("listing microphones")
    for i in range(pa.get_device_count()):
        dev = pa.get_device_info_by_index(i)
        print(i,dev['name'],dev['maxInputChannels'])
        if options['audioDevice'] == 'auto' and dev['maxInputChannels'] > 0:
            options['audioDevice'] = i
            print('  automatically set audio device to '+str(i))
if pa.get_device_count() < options['audioDevice']:
    print('audio device index is out of range (found '+str(pa.get_device_count())+' audio devices, requested #'+str(options['audioDevice'])+')')
    sys.exit()
audioDevice = pa.get_device_info_by_index(options['audioDevice'])
if audioDevice['maxInputChannels'] <= 0:
    print('audio device has no input channels! aborting')
    print('(use "arecord -l" to check available devices)')
    sys.exit()
audioOptions = {
    'deviceIndex': audioDevice['index'],
    'sampleRate': int(audioDevice['defaultSampleRate']),
    'inputChannels': 1,
}


# find videos:
videoFiles = [f for f in os.listdir(options['videoPath']) if os.path.isfile(os.path.join(options['videoPath'], f)) and f.lower().endswith(options['videoExtension'])]


if options['verbose']:
    print('')
    print('---------')
    print('')
    print('-- options --')
    print(options)
    print('')
    print('-- audio options --')
    print(audioOptions)
    print('')
    print('-- video files --')
    print(str(len(videoFiles))+' videos found')
    print('')
    print('---------')
    print('')


def drawDebugRect( im, x, y, w, h, p, c ):

    lineWidth = 1

    if p < 0.0:
        p = 0.0
    elif p > 1.0:
        p = 1.0

    filledHeight = int(h * p)

    cv2.rectangle( im, (x,y), (x+w, y+h), c, lineWidth )
    cv2.rectangle( im, (x,y+h-filledHeight), (x+w, y+h), c, -1 )



class VideostreamProcessor():

    def __init__(self):

        self.running = True
        self.fpsMeasurement = options['fps']

        self.streams = []
        self.index = 0

        self.videos = []

        for i in range(options['videostreamCount']):
            self.streams.append( self.loadVideo() )


    def start(self):
        t = Thread(target=self.update, args=())
        t.daemon = True
        t.start()
        return self


    def loadVideo(self):

        if len(self.videos) <= 1:
            if options['verbose']:
                print('resetting videolist')
            self.videos = videoFiles.copy()
            random.shuffle(self.videos)

        videoFile = self.videos.pop(1)

        videoIn = cv2.VideoCapture(options['videoPath']+videoFile)

        # we currently start always at the beginning of the video; seeking may add framedrops
        #maxFrameCount = videoIn.get(cv2.CAP_PROP_FRAME_COUNT)
        #if maxFrameCount > 100:
        #    startFrame = random.randint(0, maxFrameCount-100)
        #    videoIn.set( cv2.CAP_PROP_POS_FRAMES, startFrame )

        if options['verbose']:
            print('loading new video "'+str(videoFile)+'" ('+str(len(self.videos))+' videos left in list)')

        stream = {
            'queue': Queue(maxsize=options['videostreamMaxQueueSize']),
            'videoIn': videoIn,
            'videofile': videoFile,
        }

        return stream


    def update(self):

        previousTime = currentTime = time.time()
        targetTime = 1./options['fps']

        while self.running:

            startTime = time.time()

            # first, load 2 frames of the current stream
            currentStream = self.streams[self.index]
            for i in range(2):
                if currentStream['queue'].full():
                    break
                self.readFrameToQueue(currentStream)

            # then fill up rest:
            for stream in self.streams:
                self.readFrameToQueue(stream)

            usedTime = time.time() - startTime
            timeLeft = targetTime-usedTime
            if timeLeft > 0.0:
                time.sleep(timeLeft)

            previousTime, currentTime = currentTime, time.time()
            fps = math.ceil(1./(currentTime-previousTime))
            self.fpsMeasurement = (self.fpsMeasurement * options['fpsSmoothing']) + (fps * (1.0-options['fpsSmoothing']))


    def stop(self):
        self.running = False
        for stream in self.streams:
            stream['videoIn'].release()


    def readFrameToQueue(self, stream):

        if stream['queue'].full():
            return

        ret, frame = stream['videoIn'].read()

        if ret == False:
            # no more frames left, loop video
            stream['videoIn'].set(cv2.CAP_PROP_POS_FRAMES, 0)
            return

        if options['grayscale']:
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)

        if options['frameResize'] == 'load':
            frame = resizeFrame(frame)

        stream['queue'].put(frame)


    def changeVideostreamIndex(self):

        randomIndex = random.randint(0, options['videostreamCount']-1)
        while True:
            randomIndex += 1
            if randomIndex >= options['videostreamCount']:
                randomIndex = 0
            if randomIndex == self.index:
                continue
            if self.streams[randomIndex]['queue'].qsize() >= 5:
                # find a stream that has at least 5 frames in its queue, then break
                break

        self.index = randomIndex
        if options['verbose']: print('change videostream to #'+str(self.index)+' ('+str(self.streams[self.index]['videofile'])+')')


    def changeVideostreamInput(self, streamIndex = False):

        if streamIndex == False:
            streamIndex = random.randint(0, options['videostreamCount']-1)

        if streamIndex == self.index:
            # don't change current stream, just abort here
            return

        # close old stream
        if options['verbose']:
            print('change video on stream', streamIndex)
        self.streams[streamIndex] = self.loadVideo()


    def getNextFrame(self, blocking = False):

        if not self.running:
            return false

        if self.streams[self.index]['queue'].empty():
            # force switch to other stream
            self.changeVideostreamIndex()

        frame = self.streams[self.index]['queue'].get(blocking)

        return frame


    def getInfo(self):

        infos = []
        for stream in self.streams:
            infos.append(stream['queue'].qsize())

        return self.index, infos, self.fpsMeasurement


    def onset(self):

        if not probabilityCheck('changeVideoStream'):
            return

        oldStream = self.index

        self.changeVideostreamIndex()

        self.changeVideostreamInput(oldStream)


class EffectProcessor():

    def __init__(self):

        self.queueInput = Queue(maxsize=1)
        self.queueOutput = Queue(maxsize=1)
        self.running = True
        self.fpsMeasurement = options['fps']

        self.kernels = {
            'edgeDetection': np.array([ [-1,-1,-1], [-1, 8,-1], [-1,-1,-1] ]),
            'sharpening':    np.array([ [ 1,-3, 1], [-1, 9,-1], [-1,-3,-1] ]),
            'emboss':    np.array([ [-3, -3,-3], [-4,-4,-4], [ 7, 8, 7] ])
        }

        self.options = {
            'colorMap': 0,
            'blur': [0,0],
            'edgeDetection': 0,
            'flip': 0,
            'sharpening': 0,
            'emboss': 0,
            'inverse': 0,
            'multiple': 0,
            'staggered': 0,
            'text': 0,
        }

        self.text = False

        self.active = options['effectsActiveList']

        self.colorMaps = []
        for colorMap in options['colorMaps']:
            self.colorMaps.append(getattr(cv2, "COLORMAP_"+colorMap))

        gamma = 1.0 # 0.0 - 1.0 --> different gamma values
        invGamma = 1.0 / gamma
        inverseLut = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
        self.luts = {
            'inverse': inverseLut[::-1]
        }

        self.staggeredFrames = []


    def start(self):
        t = Thread(target=self.update, args=())
        t.daemon = True
        t.start()
        return self


    def update(self):

        previousTime = currentTime = time.time()

        while self.running:
            frame = self.queueInput.get(True)

            frame = self.apply(frame)

            self.queueOutput.put(frame)

            previousTime, currentTime = currentTime, time.time()
            fps = math.ceil(1./(currentTime-previousTime))
            self.fpsMeasurement = (self.fpsMeasurement * options['fpsSmoothing']) + (fps * (1.0-options['fpsSmoothing']))



    def put(self, frame):
        self.queueInput.put(frame)


    def get(self):
        return self.queueOutput.get()


    def apply(self, frame):

        # inverse
        if self.active['inverse'] and self.options['inverse'] > 0:
            frame = cv2.LUT(frame, self.luts['inverse'])

        # flip
        if self.active['flip'] and self.options['flip'] > 0:
            frame = cv2.flip(frame, 1)

        # edge detection
        if self.active['edgeDetection'] and self.options['edgeDetection'] > 0:
            frame = cv2.filter2D(frame, -1, self.kernels['edgeDetection'])
            self.options['edgeDetection'] -= 1

        # blur image
        if self.active['blur'] and (self.options['blur'][0] > 1 or self.options['blur'][1] > 1):
            frame = cv2.blur(frame, (self.options['blur'][0], self.options['blur'][1]))
            self.options['blur'][0] -= 1
            if self.options['blur'][0] < 1: self.options['blur'][0] = 1
            self.options['blur'][1] -= 1
            if self.options['blur'][1] < 1: self.options['blur'][1] = 1

        # sharpening
        if self.active['sharpening'] and self.options['sharpening'] > 0:
            frame = cv2.filter2D(frame, -1, self.kernels['sharpening'])
            self.options['sharpening'] -= 1

        # emboss
        if self.active['emboss'] and self.options['emboss'] > 0:
            frame = cv2.filter2D(frame, -1, self.kernels['emboss'])
            self.options['emboss'] -= 1

        # show frame multiple times (either staggered, or the same frame)
        if self.active['staggered'] and self.options['staggered'] > 0:
            # show staggered frames

            resizeFactor = 1/self.options['staggered']
            smallFrame = cv2.resize(frame, (0,0), fx=resizeFactor, fy=resizeFactor)
            if len(self.staggeredFrames) >= self.options['staggered']*self.options['staggered']:
                # remove elements from beginning
                n = self.options['staggered']*self.options['staggered']+1-len(self.staggeredFrames)
                del self.staggeredFrames[:n]
            self.staggeredFrames.append(smallFrame)

            if len(self.staggeredFrames) >= self.options['staggered']*self.options['staggered']:
                # if we have enough frames, show grid:
                reverseStaggeredFrames = self.staggeredFrames[::-1]
                frameLines = np.array_split(reverseStaggeredFrames, self.options['staggered'])
                frameLines = np.concatenate(frameLines, axis=1)
                frame = np.concatenate(frameLines, axis=1)
                frame = frame[0:options['screenHeight'], 0:options['screenWidth']]

        elif self.active['multiple'] and self.options['multiple']:
            # show same frame multiple times

            resizeFactor = 1/self.options['multiple']
            frame = cv2.resize(frame, (0,0), fx=resizeFactor, fy=resizeFactor)
            frame = np.concatenate( [frame]*self.options['multiple'], axis=1)
            frame = np.concatenate( [frame]*self.options['multiple'], axis=0)

            frame = frame[0:options['screenHeight'], 0:options['screenWidth']]

        # tint image
        if self.active['colorMap'] and self.options['colorMap'] > 0:
            frame = cv2.applyColorMap(frame, self.colorMaps[self.options['colorMap']-1])

        # text
        if self.active['text'] and self.options['text'] > 0:
            self.options['text'] -= 1
            if self.options['text'] == 0:
                self.text = False
            else:
                if not self.text:
                    self.text = random.choice(options['texts'])
                fontSize = options['fontSize']
                fontWidth = options['fontSize']
                color = (255,255,255)
                if customFont:
                    fontSize = fontSize * 40
                    textSize = customFont.getTextSize(self.text, fontSize, fontWidth)[0]
                    textX = int((options['screenWidth'] - textSize[0]) / 2)
                    textY = int((options['screenHeight'] + textSize[1]/2) / 2)
                    customFont.putText( img=frame, text=self.text, org=(textX, textY), fontHeight=fontSize, color=color, thickness=-1, line_type=cv2.LINE_AA, bottomLeftOrigin=True )
                else:
                    textSize = cv2.getTextSize(self.text, font, fontSize, fontWidth)[0]
                    textX = int((options['screenWidth'] - textSize[0]) / 2)
                    textY = int((options['screenHeight'] - textSize[1]/2) / 2)
                    cv2.putText( img=frame, text=self.text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=color, thickness=fontWidth, lineType=cv2.LINE_AA )

        return frame


    def activate(self, effect = False):

        if not effect:
            effect = random.choice(list(self.active))

        effectCheck = effect
        if effect == 'unFlip':
            effectCheck = 'flip'
        elif effect == 'unInverse':
            effectCheck = 'inverse'
        elif effect == 'unMultiple':
            effectCheck = 'multiple'
        elif effect == 'unStaggered':
            effectCheck = 'staggered'

        if not self.active[effectCheck]:
            if options['verbose']:
                print(' (effect '+str(effect)+' is not active)')
            return

        if options['verbose']:
            print('activating effect '+str(effect))

        # set colormap
        if effect == 'colorMap':
            self.options['colorMap'] = random.randint(0, len(self.colorMaps))
            if options['verbose']: print('changed colorMap to '+str(self.options['colorMap']))

        # set blur
        elif effect == 'blur':
            self.options['blur'] = [random.randint(minVals['blur'], maxVals['blur']), random.randint(minVals['blur'], maxVals['blur'])]
            if options['verbose']: print('set blur to '+str(self.options['blur']))

        # set edge detection
        elif effect == 'edgeDetection':
            self.options['edgeDetection'] = random.randint(minVals['edgeDetection'], maxVals['edgeDetection'])
            if options['verbose']: print('set edge detection to '+str(self.options['edgeDetection']))

        # set flip
        elif effect == 'flip':
            self.options['flip'] = 1
            if options['verbose']: print('set image flip')
        # unset flip
        elif effect == 'unFlip':
            self.options['flip'] = 0
            if options['verbose']: print('reset image flip')

        # set sharpening
        elif effect == 'sharpening':
            self.options['sharpening'] = random.randint(minVals['sharpening'], maxVals['sharpening'])
            if options['verbose']: print('set sharpening to '+str(self.options['sharpening']))

        # set emboss
        elif effect == 'emboss':
            self.options['emboss'] = random.randint(minVals['emboss'], maxVals['emboss'])
            if options['verbose']: print('set emboss to '+str(self.options['emboss']))

        # set inverse
        elif effect == 'inverse':
            self.options['inverse'] = 1
            if options['verbose']: print('set inverse')
        # unset inverse
        elif effect == 'unInverse':
            self.options['inverse'] = 0
            if options['verbose']: print('reset inverse')

        # set multiple
        elif effect == 'multiple':
            self.options['multiple'] = random.randint(minVals['multiple'], maxVals['multiple'])
            if options['verbose']: print('set multiple to '+str(self.options['multiple']))
        # unset multiple
        elif effect == 'unMultiple':
            self.options['multiple'] = 0
            if options['verbose']: print('reset multiple')

        # set staggered
        elif effect == 'staggered':
            if self.options['staggered'] != 0:
                self.staggeredFrames = [] # make sure to reset the frames list
            self.options['staggered'] = random.randint(minVals['staggered'], maxVals['staggered'])
            if options['verbose']: print('set staggered to '+str(self.options['staggered']))
        # unset staggered
        elif effect == 'unStaggered':
            self.options['staggered'] = 0
            self.staggeredFrames = []
            if options['verbose']: print('reset staggered')

        # set text
        elif effect == 'text':
            self.options['text'] = random.randint(minVals['text'], maxVals['text'])
            if options['verbose']: print('set text to '+str(self.options['text']))


    def toggle(self, effect, setToBool = 'none' ):

        if effect == 'all':
            setToBool = not self.active['colorMap'] # we use the value of the first effect to toggle
            for effect in self.active:
                self.toggle(effect, setToBool)
            return

        print('setToBool '+str(setToBool))

        if setToBool == 'none':
            # toggle
            self.active[effect] = not self.active[effect]
        else:
            # set to value
            self.active[effect] = setToBool

        if effect == 'blur':
            self.options[effect] = [0,0]
        else:
            self.options[effect] = 0

        if options['verbose']:
            print('set effect '+str(effect)+' to '+str(self.active[effect]))


    def onset(self):

        # set colormap
        if probabilityCheck('changeColorMap'):
            self.activate('colorMap')

        # set blur
        if probabilityCheck('setBlur'):
            self.activate('blur')

        # set edge detection
        if probabilityCheck('setEdgeDetection'):
            self.activate('edgeDetection')

        # set flip
        if self.options['flip'] and probabilityCheck('unsetFlip'):
            self.activate('unFlip')
        elif probabilityCheck('setFlip'):
            self.activate('flip')

        # set sharpening
        if probabilityCheck('setSharpening'):
            self.activate('sharpening')

        # set emboss
        if probabilityCheck('setEmboss'):
            self.activate('emboss')

        # set inverse
        if self.options['inverse'] and probabilityCheck('unsetInverse'):
            self.activate('unInverse')
        elif probabilityCheck('setInverse'):
            self.activate('inverse')

        # set multiple
        if self.options['multiple'] and probabilityCheck('unsetMultiple'):
            self.activate('unMultiple')
        elif probabilityCheck('setMultiple'):
            self.activate('multiple')

        # set staggered
        if self.options['staggered'] and probabilityCheck('unsetStaggered'):
            self.activate('unStaggered')
        elif probabilityCheck('setStaggered'):
            self.activate('staggered')

        # set text
        if probabilityCheck('setText'):
            self.activate('text')


    def getInfo(self):
        return self.active, self.options, self.fpsMeasurement


    def stop(self):
        self.running = False


class AudioProcessor:

    def __init__(self):

        self.running = True
        self.queue = Queue()

        self.peakBuffer = np.zeros(options['fps'])
        self.peakBufferOnset = np.zeros(options['fps'])
        self.peakBufferIndex = 0

        self.bufferSize = 1024

        self.audio = pyaudio.PyAudio()
        self.stream = self.audio.open(format=pyaudio.paFloat32,
                                    input=True,
                                    channels=audioOptions['inputChannels'],
                                    input_device_index=audioOptions['deviceIndex'],
                                    frames_per_buffer=self.bufferSize,
                                    rate=audioOptions['sampleRate'],
                                    stream_callback=self.readAudioFrames)

        hop_s = self.bufferSize
        win_s = hop_s * 2
        self.tempo = aubio.tempo(method='default', buf_size=win_s, hop_size=hop_s, samplerate=audioOptions['sampleRate'])

        if options['verbose']:
            print('start aubio tempo detection with deviceid: '+str(audioOptions['deviceIndex'])+' / samplerate: '+str(audioOptions['sampleRate'])+' / buffersize: '+str(self.bufferSize)+' / hop_s: '+str(hop_s))


    def start(self):
        return self


    def readAudioFrames( self, in_data, frame_count, time_info, status ):

        signal = np.frombuffer(in_data, dtype=np.float32)

        beat = False

        tempo = self.tempo(signal)
        if tempo:
            beat = True

        peak = np.abs(np.max(signal)-np.min(signal))*options['audioDisplayScaling']

        self.peakBuffer[self.peakBufferIndex] = peak
        self.peakBufferOnset[self.peakBufferIndex] = beat

        self.peakBufferIndex += 1
        if self.peakBufferIndex >= len(self.peakBuffer):
            self.peakBufferIndex = 0

        if beat:
            self.queue.put(True)

        return (in_data, pyaudio.paContinue)


    def getInfo(self):
        return self.peakBuffer, self.peakBufferOnset, self.peakBufferIndex, self.tempo.get_bpm()


    def isBeat(self):

        if self.queue.qsize() > 0:
            return self.queue.get()

        return False

    def stop(self):
        self.stream.stop_stream()
        self.stream.close()
        self.audio.terminate()



def probabilityCheck( key ):
    if random.randint(0, probabilities[key])+1 <= options['sensitivity']*10:
        return True
    else:
        return False


def debugDisplay( im, onset ):

    textX = 30

    if options['debugFPS']:
        color = (0,255,0)

        if fpsMeasurement < options['fps']*0.8:
            color = (0,0,255)
        elif fpsMeasurement < options['fps']*0.9:
            color = (0,255,255)

        text = 'Main FPS: '+str(int(fpsMeasurement))
        textsize = cv2.getTextSize(text, options['debugFont'], 1, 1)[0]
        cv2.putText( im, text, (options['screenWidth']-textsize[0]-10, textX), options['debugFont'], 1, color, 1, cv2.LINE_AA )

        textX += 30


    if options['effectsActive'] and options['debugEffects']:
        activeEffects, effectOptions, effectsFpsMeasurement = effects.getInfo()

        h = 50
        x = 10
        y = 10

        for key, val in effectOptions.items():
            text = key

            if activeEffects[key]:
                color = (255,255,255)
            else:
                color = (0,0,0)
                val = 0

            maxVal = 1

            w = 20
            tX = x

            if key == 'colorMap':
                maxVal = len(options['colorMaps'])
                text = 'col'
            elif key == 'blur':
                maxVal = maxVals['blur']
                if not activeEffects[key]:
                    val = (0,0)

                w = 15

                filledPercent = val[0]/maxVal
                drawDebugRect( im, x, y, w, h, filledPercent, color )
                x += w+2
                tX = x-int(w/2)
                val = val[1]

            elif key == 'edgeDetection':
                maxVal = maxVals['edgeDetection']
                text = 'edg'
            elif key == 'sharpening':
                maxVal = maxVals['sharpening']
                text = 'shrp'
            elif key == 'emboss':
                maxVal = maxVals['emboss']
                text = 'emb'
            elif key == 'text':
                maxVal = maxVals['text']
                text = 'txt'
            elif key == 'inverse':
                text = 'inv'
            elif key == 'multiple':
                maxVal = maxVals['multiple']
                text = 'mult'
            elif key == 'staggered':
                maxVal = maxVals['staggered']
                text = 'stag'

            filledPercent = val/maxVal

            drawDebugRect( im, x, y, w, h, filledPercent, color )
            textsize = cv2.getTextSize(text, options['debugFont'], 0.4, 1)[0]
            tX += int(w/2)-int(textsize[0]/2)
            cv2.putText( im, text, (tX, y+h+8), options['debugFont'], 0.4, color, 1, cv2.LINE_AA )

            x += w+5


        if options['effectsMultithreaded']:
            color = (0,255,0)
            if effectsFpsMeasurement < options['fps']*0.8:
                color = (0,0,255)
            elif effectsFpsMeasurement < options['fps']*0.9:
                color = (0,255,255)
            effectsFpsMeasurement = str(int(effectsFpsMeasurement))
        else:
            color = (255,255,255)
            effectsFpsMeasurement = '**'

        text = 'Effects FPS: '+effectsFpsMeasurement
        textsize = cv2.getTextSize(text, options['debugFont'], 1, 1)[0]
        cv2.putText( im, text, (options['screenWidth']-textsize[0]-10, textX), options['debugFont'], 1, color, 1, cv2.LINE_AA )

        textX += 30


    if options['debugTiming']:

        frameTime = usedTime + additionalFrameTime

        color = (0,255,0)
        if frameTime > targetTime * 0.95:
            color = (0,0,255)
        elif frameTime > targetTime*0.8:
            color = (0,255,255)

        filledPercent = float(frameTime)/float(targetTime)

        w = 30
        h = 100
        x = options['screenWidth'] - w - 10
        y = options['screenHeight'] - h - 10

        drawDebugRect( im, x, y, w, h, filledPercent, color )

    if options['debugStreams']:
        streamIndex, queueSizes, streamsFpsMeasurement = videostreams.getInfo()

        w = 10
        h = 100
        x = 10
        y = options['screenHeight'] - h - 10

        for i, queueSize in enumerate(queueSizes):
            color = (0,255,0)
            if i == streamIndex:
                color = (0,0,255)
            filledPercent = float(queueSize/options['videostreamMaxQueueSize'])
            drawDebugRect( im, x, y, w, h, filledPercent, color )
            x += w+5

        color = (0,255,0)
        if streamsFpsMeasurement < options['fps']*0.8:
            color = (0,0,255)
        elif streamsFpsMeasurement < options['fps']*0.9:
            color = (0,255,255)

        text = 'VideoStreams FPS: '+str(int(streamsFpsMeasurement))
        textsize = cv2.getTextSize(text, options['debugFont'], 1, 1)[0]
        cv2.putText( im, text, (options['screenWidth']-textsize[0]-10, textX), options['debugFont'], 1, color, 1, cv2.LINE_AA )

        textX += 30


    if options['debugAudio']:

        data, onsetData, index, bpm = audio.getInfo()
        index -= 1
        if index < 0:
            index = options['fps']-1

        w = math.ceil(options['screenWidth']/len(data))
        x = options['screenWidth']-w
        y = int(options['screenHeight'] / 2)

        for i in range(len(data)):
            h = int(data[index])
            o = onsetData[index]

            color = (255,255,255)
            if o:
                color = (255,0,0)

            cv2.rectangle( im, (x,y), (x+w, y-h), color, -1 )

            x += w

            index += 1
            if index >= len(data):
                index = 0
            if x >= options['screenWidth']:
                x = 0

        color = (255,255,255)


        text = 'BPM: '+str(int(bpm))+'/'+str(int(bpm*2))
        textsize = cv2.getTextSize(text, options['debugFont'], 1, 1)[0]
        cv2.putText( im, text, (options['screenWidth']-textsize[0]-10, textX), options['debugFont'], 1, color, 1, cv2.LINE_AA )

        textX += 30


    if options['debugOnset']:

        w = 100
        h = 100
        x = options['screenWidth'] - w - 70
        y = options['screenHeight'] - h - 10

        filledPercent = 0.0
        color = (255,255,255)
        if onset:
            filledPercent = 1.0
            color = (0,0,255)

        drawDebugRect( im, x, y, w, h, filledPercent, color )


    return im


def resizeFrame( frame ):

    if not options['frameResize']:
        return frame

    frameHeight, frameWidth, frameChannels = frame.shape
    targetWidth = options['screenWidth']
    targetHeight = int(targetWidth * frameHeight/frameWidth)
    if targetHeight < options['screenHeight']:
        targetHeight = options['screenHeight']
        targetWidth = int(targetHeight * frameWidth/frameHeight)

    marginX = int((targetWidth - options['screenWidth'])/2)
    marginY = int((targetHeight - options['screenHeight'])/2)

    frame = cv2.resize( frame, (targetWidth, targetHeight) )
    frame = frame[marginY:marginY+options['screenHeight'], marginX:marginX+options['screenWidth']]

    return frame


def messagesDisplay( frame, messages ):

    textX = options['screenHeight'] - 10

    for message in messages:
        text = message['text']
        textsize = cv2.getTextSize(text, options['debugFont'], 1, 1)[0]
        cv2.putText( frame, text, (10, textX), options['debugFont'], 1, (255,255,255), 1, cv2.LINE_AA )
        textX -= 30

        if frameNumber > message['lifeTime']:
            messages.remove(message)

    return frame


def newMessage( text ):

    message = {
        'text': text,
        'lifeTime': frameNumber + options['fps']
    }

    messages.append(message)


targetTime = 1./options['fps']
previousTime = currentTime = time.time()
usedTime = 0

fpsMeasurement = options['fps']

videostreams = VideostreamProcessor().start()


if options['verbose']:
    print('init -- sleep for '+str(options['initSleepTime'])+' seconds')

time.sleep(options['initSleepTime'])

if options['effectsActive']:
    effects = EffectProcessor()
    if options['effectsMultithreaded']:
        effects.start()

audio = AudioProcessor().start()

time.sleep(0.5)

if options['effectsActive'] and options['effectsMultithreaded']:
    if options['frameResize'] == 'post':
        effects.put(videostreams.getNextFrame(True))
    else:
        effects.put(startupImage)

frameNumber = 0
additionalFrameTime = 0

frameCountIn30Seconds = options['fps']*30
frameCountIn10Seconds = options['fps']*10

paused = False

messages = []

# main loop
while True:

    startTime = time.time()

    if paused:

        frame = lastFrame.copy()

        font = cv2.FONT_HERSHEY_TRIPLEX
        text = "paused"
        fontSize = 2
        fontWidth = 3
        color = (185,107,250)
        if customFont:
            fontSize = fontSize * 40
            textSize = customFont.getTextSize(text, fontSize, fontWidth)[0]
            textX = int((options['screenWidth'] - textSize[0]) / 2)
            textY = int((options['screenHeight'] - textSize[1]) / 2)
            customFont.putText( img=frame, text=text, org=(textX, textY), fontHeight=fontSize, color=color, thickness=-1, line_type=cv2.LINE_AA, bottomLeftOrigin=True )
        else:
            textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
            textX = int((options['screenWidth'] - textSize[0]) / 2)
            textY = int((options['screenHeight'] - textSize[1]) / 2)
            cv2.putText( img=frame, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=color, thickness=fontWidth, lineType=cv2.LINE_AA )

    else:
        frame = videostreams.getNextFrame()
        if type(frame) == type(None): # no frame retreived, use last frame
            frame = lastFrame

        lastFrame = frame.copy()

        if options['frameResize'] == 'pre':
            frame = resizeFrame(frame)

        if options['effectsActive']:
            if options['effectsMultithreaded']:
                nextFrame = frame
                frame = effects.get()
                effects.put(nextFrame)
            else:
                frame = effects.apply(frame)

        if options['frameResize'] == 'post':
            frame = resizeFrame(frame)

        onset = audio.isBeat()

    frame = debugDisplay(frame, onset)

    if len(messages) > 0:
        frame = messagesDisplay(frame, messages)

    cv2.imshow(options['windowName'], frame)

    usedTime = time.time() - startTime
    timeLeft = targetTime-usedTime
    sleepTime = timeLeft - additionalFrameTime # this is the approximate time that the rest of this loop takes
    sleepTime = int(sleepTime*1000)
    if sleepTime < 1:
        sleepTime = 1

    key = cv2.waitKey(sleepTime)

    midTime = time.time()

    previousTime, currentTime = currentTime, time.time()
    fps = round(1./(currentTime-previousTime))
    fpsMeasurement = (fpsMeasurement * options['fpsSmoothing']) + (fps * (1.0-options['fpsSmoothing']))

    if key == 27: # escape
        newMessage('exiting')
        break

    elif key == 32: # space
        newMessage('fake beat')
        onset = True

    elif key&0xFF == ord('i'):
        newMessage('change random videostream index')
        videostreams.changeVideostreamIndex()

    elif key&0xFF == ord('c'):
        newMessage('change random videostream input')
        videostreams.changeVideostreamInput()

    elif key&0xFF == ord('1'):
        newMessage('toggle colorMap effect')
        effects.toggle('colorMap')
    elif key&0xFF == ord('2'):
        newMessage('toggle blur effect')
        effects.toggle('blur')
    elif key&0xFF == ord('3'):
        newMessage('toggle edgeDetection effect')
        effects.toggle('edgeDetection')
    elif key&0xFF == ord('4'):
        newMessage('toggle flip effect')
        effects.toggle('flip')
    elif key&0xFF == ord('5'):
        newMessage('toggle sharpening effect')
        effects.toggle('sharpening')
    elif key&0xFF == ord('6'):
        newMessage('toggle emboss effect')
        effects.toggle('emboss')
    elif key&0xFF == ord('7'):
        newMessage('toggle inverse effect')
        effects.toggle('inverse')
    elif key&0xFF == ord('8'):
        newMessage('toggle multiple effect')
        effects.toggle('multiple')
    elif key&0xFF == ord('9'):
        newMessage('toggle staggered effect')
        effects.toggle('staggered')
    elif key&0xFF == ord('0'):
        newMessage('toggle text effect')
        effects.toggle('text')
    elif key&0xFF == ord('a'):
        newMessage('toggle all effects')
        effects.toggle('all')

    elif key&0xFF == ord('q'):
        newMessage('toggle fps debug display')
        options['debugFPS'] = not options['debugFPS']
    elif key&0xFF == ord('w'):
        newMessage('toggle timing debug display')
        options['debugTiming'] = not options['debugTiming']
    elif key&0xFF == ord('e'):
        newMessage('toggle videostreams debug display')
        options['debugStreams'] = not options['debugStreams']
    elif key&0xFF == ord('r'):
        newMessage('toggle effects debug display')
        options['debugEffects'] = not options['debugEffects']
    elif key&0xFF == ord('t'):
        newMessage('toggle audio debug display')
        options['debugAudio'] = not options['debugAudio']
    elif key&0xFF == ord('z'):
        newMessage('toggle onset debug display')
        options['debugOnset'] = not options['debugOnset']

    elif key&0xFF == ord('p'):
        paused = not paused
        if paused:
            newMessage('pause rendering')
        else:
            newMessage('un-pause rendering')

    elif key&0xFF == ord('d'):
        newMessage('toggle all debug displays')
        newBool = not options['debugFPS']
        options['debugFPS'] = newBool
        options['debugTiming'] = newBool
        options['debugStreams'] = newBool
        options['debugEffects'] = newBool
        options['debugAudio'] = newBool
        options['debugOnset'] = newBool

    elif key&0xFF == ord(','):
        options['sensitivity'] -= 0.05
        if options['sensitivity'] < 0:
            options['sensitivity'] = 0.0
        if options['verbose']:
            print('set sensitivity to '+str(options['sensitivity']))
        newMessage('decrease sensitivity to '+str(options['sensitivity']))
    elif key&0xFF == ord('.'):
        options['sensitivity'] += 0.05
        if options['sensitivity'] > 1:
            options['sensitivity'] = 1.0
        if options['verbose']:
            print('set sensitivity to '+str(options['sensitivity']))
        newMessage('increase sensitivity to '+str(options['sensitivity']))

    if onset:
        videostreams.onset()

        if options['effectsActive']:
            effects.onset()

    frameNumber += 1

    additionalFrameTime = time.time() - midTime


if options['verbose']:
    print('shutting down ...')

if options['effectsActive'] and options['effectsMultithreaded']:
    effects.stop()

videostreams.stop()
audio.stop()

cv2.destroyAllWindows()

print('bye!')

